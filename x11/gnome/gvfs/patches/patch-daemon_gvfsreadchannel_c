$OpenBSD: patch-daemon_gvfsreadchannel_c,v 1.1 2013/04/05 14:07:31 ajacoutot Exp $

From c9b8fc094d7a95386641901957cca890d5345aa1 Mon Sep 17 00:00:00 2001
From: Alexander Larsson <alexl@redhat.com>
Date: Fri, 05 Apr 2013 12:06:37 +0000
Subject: Fix readahead behaviour

From e0941e88ffdd3b4d89e8d2db9dabbb86ff9d81e1 Mon Sep 17 00:00:00 2001
From: Alexander Larsson <alexl@redhat.com>
Date: Fri, 05 Apr 2013 12:33:21 +0000
Subject: daemons: Tweak read sizes

--- daemon/gvfsreadchannel.c.orig	Fri Apr  5 15:40:41 2013
+++ daemon/gvfsreadchannel.c	Fri Apr  5 15:42:53 2013
@@ -96,27 +96,38 @@ read_channel_close (GVfsChannel *channel)
 } 
 
 /* Always request large chunks. Its very inefficient
-   to do network requests for smaller chunks. */
+ * to do network requests for smaller chunks.
+ *
+ * gstreamer tends to do 4k reads and seeks, and
+ * the first read when sniffing is also small, so
+ * it makes sense to never read more that 4k
+ * (one page) on the first read. It should not affect
+ * long-file copy performance anyway.
+ */
 static guint32
 modify_read_size (GVfsReadChannel *channel,
 		  guint32 requested_size)
 {
   guint32 real_size;
-  
+
   if (channel->read_count <= 1)
-    real_size = 16*1024;
+    real_size = 4*1024;
   else if (channel->read_count <= 2)
+    real_size = 8*1024;
+  else if (channel->read_count <= 3)
+    real_size = 16*1024;
+  else if (channel->read_count <= 4)
     real_size = 32*1024;
   else
     real_size = 64*1024;
-  
+
   if (requested_size > real_size)
-    real_size = requested_size;
+      real_size = requested_size;
 
   /* Don't do ridicoulously large requests as this
      is just stupid on the network */
-  if (real_size > 512 * 1024)
-    real_size = 512 * 1024;
+  if (real_size > 128 * 1024)
+    real_size = 128 * 1024;
 
   return real_size;
 }
@@ -209,7 +220,20 @@ read_channel_readahead (GVfsChannel  *channel,
       read_job = G_VFS_JOB_READ (job);
       read_channel = G_VFS_READ_CHANNEL (channel);
 
-      if (read_job->data_count != 0)
+      /* If the last operation was a read and it succeeded then we
+	 might want to start a readahead. We don't do this for the
+	 first read op as we're not sure we're streaming larger
+	 parts of the file yet. However, after the second read we
+	 queue a readahead read. After this the reading side will
+	 constantly be one read operation behind, such that by
+	 the time the second read operation is done and a third
+	 read() is done we will send a read request but start
+	 reading the readahead data, and after that is done
+	 send a new request but start reading the result of the
+	 previous read request. This way the reading will be
+	 fully pipelined. */
+      if (read_job->data_count != 0 &&
+	  read_channel->read_count == 2)
 	{
 	  read_channel->read_count++;
 	  readahead_job = g_vfs_job_read_new (read_channel,
@@ -218,7 +242,7 @@ read_channel_readahead (GVfsChannel  *channel,
 					      g_vfs_channel_get_backend (channel));
 	}
     }
-  
+
   return readahead_job;
 }
 
